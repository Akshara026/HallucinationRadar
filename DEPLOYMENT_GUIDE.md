# ğŸš€ HallucinationRadar - Deployment Guide

## âœ… Deployment Status: COMPLETE

The HallucinationRadar project has been successfully deployed and is ready for use!

---

## ğŸ“‹ Deployment Checklist

### Environment Setup âœ…

- [x] Python 3.12.2 verified
- [x] All dependencies installed
- [x] spaCy en_core_web_sm model downloaded
- [x] Data directories created
- [x] Configuration verified
- [x] All core imports tested
- [x] Web UI module tested
- [x] Main API module tested
- [x] Launch scripts created

### Project Structure âœ…

- [x] 17 Python modules
- [x] 1 Configuration file
- [x] 6 Documentation files
- [x] Core modules (11 files)
- [x] Entry points (3 files)

---

## ğŸš€ Getting Started

### Option 1: Launch Web Interface (Easiest)

**Windows:**

```bash
# Double-click launch_web.bat or:
python app.py
```

**Linux/Mac:**

```bash
python app.py
```

Then open your browser to: **http://localhost:7860**

### Option 2: Use Python API

```python
from main import HallucinationRadar

# Initialize
radar = HallucinationRadar()

# Load your documents
radar.load_documents()

# Verify an answer
result = radar.verify_answer(
    question="What is the capital of France?",
    answer="Paris is the capital of France."
)

# Check results
print(f"Score: {result['truthfulness_score']:.1f}")
print(f"Category: {result['report']['score_category']}")
```

### Option 3: Run Examples

```bash
python QUICKSTART.py
```

---

## ğŸ“ Project Structure

```
HallucinationRadar/
â”œâ”€â”€ app.py                      # Web interface (Gradio)
â”œâ”€â”€ main.py                     # Python API
â”œâ”€â”€ deploy.py                   # Deployment script
â”œâ”€â”€ launch_web.bat              # Windows launcher
â”‚
â”œâ”€â”€ Core Modules/
â”‚   â”œâ”€â”€ llm/answer_generator.py
â”‚   â”œâ”€â”€ claims/claim_extractor.py
â”‚   â”œâ”€â”€ retireval/
â”‚   â”‚   â”œâ”€â”€ doc_loader.py
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ web_search.py
â”‚   â”œâ”€â”€ verification/claim_verifier.py
â”‚   â”œâ”€â”€ scoring/truthfulness.py
â”‚   â”œâ”€â”€ highlighting/highlighter.py
â”‚   â”œâ”€â”€ evaluation/fever_eval.py
â”‚   â””â”€â”€ utils/text_utils.py
â”‚
â”œâ”€â”€ Configuration/
â”‚   â””â”€â”€ config/settings.yaml
â”‚
â”œâ”€â”€ Documentation/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ BEST_PRACTICES.md
â”‚   â”œâ”€â”€ PROJECT_COMPLETION.md
â”‚   â”œâ”€â”€ INDEX.md
â”‚   â””â”€â”€ FINAL_REPORT.md
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ documents/              # â† Add your evidence documents here
â”‚   â””â”€â”€ vector_store/           # Auto-generated embeddings
â”‚
â””â”€â”€ Requirements/
    â””â”€â”€ requirements.txt
```

---

## ğŸ“‚ Adding Evidence Documents

### Supported Formats

- **PDF Files** (.pdf)
- **Text Files** (.txt)
- **JSON Files** (.json)

### Steps:

1. Prepare your documents
2. Place them in: `data/documents/`
3. Restart the application (if running)
4. Documents will be automatically indexed

### Example Structure:

```
data/documents/
â”œâ”€â”€ wikipedia/
â”‚   â”œâ”€â”€ science.txt
â”‚   â”œâ”€â”€ history.txt
â”‚   â””â”€â”€ geography.txt
â”œâ”€â”€ academic_papers/
â”‚   â”œâ”€â”€ paper1.pdf
â”‚   â””â”€â”€ paper2.pdf
â””â”€â”€ custom_knowledge/
    â”œâ”€â”€ facts.json
    â””â”€â”€ definitions.txt
```

---

## âš™ï¸ Configuration

### Quick Configuration

Edit `config/settings.yaml` to customize:

**For Faster Processing (CPU):**

```yaml
llm:
  model_name: "gpt2"
  max_length: 128

embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cpu"
```

**For Better Accuracy (if GPU available):**

```yaml
llm:
  model_name: "facebook/opt-350m"
  max_length: 256

embedding:
  model_name: "sentence-transformers/all-mpnet-base-v2"
  device: "cuda"
```

**Adjust Verification Sensitivity:**

```yaml
verification:
  support_threshold: 0.7 # Higher = stricter
  uncertainty_threshold: 0.4 # Lower = more lenient
```

---

## ğŸ¯ Web Interface Guide

### Tab 1: Verify Answer

- Enter a question
- Provide an answer to verify
- Get truthfulness score, claim breakdown, and risk highlights

### Tab 2: Generate & Verify

- Enter a question
- System generates an answer
- Returns verification results

### Tab 3: Batch Verify

- Upload CSV with Question, Answer columns
- Process multiple items
- Download results CSV

### Tab 4: About

- Project information
- Feature overview
- Usage guidelines

---

## ğŸ“Š Output Interpretation

### Truthfulness Score

- **80-100**: ğŸŸ¢ Highly Reliable
- **60-79**: ğŸŸ¡ Reliable
- **40-59**: ğŸŸ  Uncertain
- **20-39**: ğŸ”´ Unreliable
- **0-19**: ğŸ”´ğŸ”´ Highly Unreliable

### Claim Status

- âœ… **Supported**: Strong evidence
- âš ï¸ **Partially Supported**: Some evidence
- âŒ **Unsupported**: No evidence
- ğŸš¨ **Conflicting**: Contradicting evidence

---

## ğŸ”§ Troubleshooting

### Issue: "No documents loaded"

**Solution**: Add documents to `data/documents/` and restart

### Issue: Out of memory

**Solution**: In config/settings.yaml, set device to "cpu" and use smaller models

### Issue: Slow inference

**Solution**:

- Enable GPU (if available)
- Use smaller embedding model
- Reduce batch size

### Issue: Module import errors

**Solution**:

```bash
pip install -r requirements.txt --force-reinstall
python -m spacy download en_core_web_sm
```

### Issue: Port already in use

**Solution**: Change port in app.py or kill existing process:

```bash
# Find process on port 7860
lsof -i :7860  # Mac/Linux
netstat -ano | findstr :7860  # Windows
```

---

## ğŸ“ˆ Performance Optimization

### CPU Mode (Recommended for most users)

```python
radar = HallucinationRadar()
# Automatically uses CPU if GPU not available
```

### GPU Mode (for faster processing)

```yaml
embedding:
  device: "cuda"
llm:
  model_name: "facebook/opt-1.3b"
```

### Batch Processing

```python
qa_pairs = [
    {'question': 'Q1', 'answer': 'A1'},
    {'question': 'Q2', 'answer': 'A2'},
    # ...
]
results = radar.batch_verify(qa_pairs)
```

---

## ğŸ”’ Security Considerations

- âœ… Keep sensitive documents in secure folder
- âœ… Don't share results containing PII
- âœ… Use in controlled environments
- âœ… Validate document sources

---

## ğŸ“Š Monitoring

### Enable Logging

In Python code:

```python
import logging
logging.basicConfig(level=logging.INFO)
```

### Check Logs

Logs are stored in: `logs/hallucination_radar.log`

### Monitor Metrics

```python
from main import HallucinationRadar

radar = HallucinationRadar()
radar.load_documents()

# Track scores
results = radar.batch_verify(qa_pairs)
avg_score = sum(r['truthfulness_score'] for r in results) / len(results)
print(f"Average Score: {avg_score:.1f}")
```

---

## ğŸ”„ Maintenance

### Regular Tasks

1. **Update Documents**: Add new evidence regularly
2. **Check Performance**: Monitor inference times
3. **Review Results**: Validate accuracy
4. **Update Models**: Periodically update embedding models

### Backup Important Data

```bash
# Backup vector store
cp -r data/vector_store/ data/vector_store.backup/

# Backup configuration
cp config/settings.yaml config/settings.yaml.backup
```

---

## ğŸš€ Deployment Environments

### Local Development

```bash
python app.py
# Access: http://localhost:7860
```

### Docker (Optional - for production)

Create a `Dockerfile`:

```dockerfile
FROM python:3.12

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt && \
    python -m spacy download en_core_web_sm

COPY . .

EXPOSE 7860
CMD ["python", "app.py"]
```

Build and run:

```bash
docker build -t hallucination-radar .
docker run -p 7860:7860 hallucination-radar
```

### Cloud Deployment (Heroku Example)

1. Create `Procfile`: `web: python app.py`
2. Create `runtime.txt`: `python-3.12.2`
3. Deploy: `git push heroku main`

---

## ğŸ“ Support & Resources

### Documentation

- ğŸ“– **README.md** - Full project overview
- ğŸ“– **BEST_PRACTICES.md** - Usage patterns
- ğŸ“– **QUICKSTART.py** - Code examples
- ğŸ“– **INDEX.md** - Project organization

### Getting Help

1. Check documentation files
2. Review example code
3. Check configuration options
4. Review troubleshooting section

---

## âœ¨ What's Included

### Features

âœ… LLM answer generation  
âœ… NLP claim extraction  
âœ… Multi-format document loading  
âœ… Semantic search  
âœ… Evidence-based verification  
âœ… Truthfulness scoring  
âœ… Risk highlighting  
âœ… Batch processing  
âœ… Web interface  
âœ… Python API

### Tools

âœ… Gradio web UI  
âœ… Python API  
âœ… Command-line examples  
âœ… Deployment script  
âœ… Launch scripts  
âœ… Comprehensive documentation

---

## ğŸ¯ Next Steps

1. **Add Documents**: Place files in `data/documents/`
2. **Configure Settings**: Edit `config/settings.yaml` if needed
3. **Start Using**: Run `python app.py`
4. **Integrate**: Use in your workflows

---

## ğŸ“ Deployment Verification

To verify deployment is complete:

```bash
# Check all components
python verify_project.py

# Test imports
python -c "from main import HallucinationRadar; print('âœ“ Ready!')"

# Run examples
python QUICKSTART.py
```

---

## ğŸ‰ You're Ready!

**Deployment Successful!** âœ…

HallucinationRadar is now deployed and ready for production use.

- ğŸŒ **Web UI**: `python app.py` â†’ http://localhost:7860
- ğŸ **Python API**: `from main import HallucinationRadar`
- ğŸ“š **Documentation**: See README.md and guides
- ğŸ’¡ **Examples**: Run QUICKSTART.py

Enjoy fact-checking with HallucinationRadar! ğŸš€
